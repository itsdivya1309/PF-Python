{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f45b6e0e-57b4-44df-972c-a4c411e63ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "from aeon.classification.base import BaseClassifier\n",
    "from aeon.distances import distance\n",
    "\n",
    "\n",
    "class Node:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_id: int,\n",
    "        _is_leaf: bool,\n",
    "        label=None,\n",
    "        class_distribution=None,\n",
    "        splitter=None,\n",
    "    ):\n",
    "        self.node_id = node_id\n",
    "        self._is_leaf = _is_leaf\n",
    "        self.label = label\n",
    "        self.splitter = splitter\n",
    "        self.class_distribution = class_distribution or {}\n",
    "        self.children = {}\n",
    "\n",
    "\n",
    "class ProximityTree(BaseClassifier):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_splitters: int = 5,\n",
    "        max_depth: int = None,\n",
    "        min_samples_split: int = 2,\n",
    "        random_state: int = None,\n",
    "        n_jobs: int = 1,\n",
    "        verbose: int = 0,\n",
    "    ) -> None:\n",
    "        self.n_splitters = n_splitters\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.rng = np.random.default_rng(random_state)\n",
    "        self.n_jobs = n_jobs\n",
    "        self.verbose = verbose\n",
    "        super().__init__()\n",
    "\n",
    "    def get_parameter_value(self, X):\n",
    "        \"\"\"Generate random parameter values.\n",
    "\n",
    "        For a list of distance measures, generate a dictionary\n",
    "        of parameterized distances.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray of shape (n_cases, n_timepoints)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        distance_param : a dictionary of distances and their\n",
    "        parameters.\n",
    "        \"\"\"\n",
    "        X_std = X.std()\n",
    "        param_ranges = {\n",
    "            \"euclidean\": {},\n",
    "            \"dtw\": {\"window\": (0, 0.25)},\n",
    "            \"ddtw\": {\"window\": (0, 0.25)},\n",
    "            \"wdtw\": {\"g\": (0, 1)},\n",
    "            \"wddtw\": {\"g\": (0, 1)},\n",
    "            \"erp\": {\"g\": (X_std / 5, X_std)},\n",
    "            \"lcss\": {\"epsilon\": (X_std / 5, X_std), \"window\": (0, 0.25)},\n",
    "        }\n",
    "        random_params = {}\n",
    "        for measure, ranges in param_ranges.items():\n",
    "            random_params[measure] = {\n",
    "                param: np.round(self.rng.uniform(low, high), 3)\n",
    "                for param, (low, high) in ranges.items()\n",
    "            }\n",
    "        # For TWE\n",
    "        lmbda = self.rg.integers(0, 9)\n",
    "        exponent_range = np.arange(1, 6)  # Exponents from -5 to 1 (inclusive)\n",
    "        random_exponent = self.rng.choice(exponent_range)\n",
    "        nu = 1 / 10**random_exponent\n",
    "        random_params[\"twe\"] = {\"lmbda\": lmbda, \"nu\": nu}\n",
    "\n",
    "        # For MSM\n",
    "        base = 10\n",
    "        # Exponents from -2 to 2 (inclusive)\n",
    "        exponents = np.arange(-2, 3, dtype=np.float64)\n",
    "        # Randomly select an index from the exponent range\n",
    "        random_index = self.rng.integers(0, len(exponents))\n",
    "        c = base ** exponents[random_index]\n",
    "        random_params[\"msm\"] = {\"c\": c}\n",
    "\n",
    "        return random_params\n",
    "\n",
    "    def get_candidate_splitter(self, X, y):\n",
    "        \"\"\"Generate candidate splitter.\n",
    "\n",
    "        Takes a time series dataset and a set of parameterized\n",
    "        distance measures to create a candidate splitter, which\n",
    "        contains a parameterized distance measure and a set of exemplars.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray shape (n_cases, n_timepoints)\n",
    "            The training input samples.\n",
    "        y : np.array shape (n_cases,) or (n_cases,1)\n",
    "        parameterized_distances : dictionary\n",
    "            Contains the distances and their parameters.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        splitter : list of two dictionaries\n",
    "            A distance and its parameter values and a set of exemplars.\n",
    "        \"\"\"\n",
    "        _X = X\n",
    "        _y = y\n",
    "\n",
    "        exemplars = {}\n",
    "        for label in np.unique(_y):\n",
    "            y_new = _y[_y == label]\n",
    "            X_new = _X[_y == label]\n",
    "            id = np.random.randint(0, X_new.shape[0])\n",
    "            exemplars[y_new[id]] = X_new[id, :]\n",
    "\n",
    "        # Create a list with first element exemplars and second element a\n",
    "        # random parameterized distance measure\n",
    "        parameterized_distances = self.get_parameter_value(X)\n",
    "        n = np.random.randint(0, 9)\n",
    "        dist = list(parameterized_distances.keys())[n]\n",
    "        splitter = [exemplars, {dist: parameterized_distances[dist]}]\n",
    "\n",
    "        return splitter\n",
    "\n",
    "    def gini(self, y):\n",
    "        \"\"\"Get gini score at a specific node.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : 1d numpy array\n",
    "            array of class labels\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        score : float\n",
    "            gini score for the set of class labels (i.e. how pure they are). A\n",
    "            larger score means more impurity. Zero means\n",
    "            pure.\n",
    "        \"\"\"\n",
    "        # get number instances at node\n",
    "        n_instances = y.shape[0]\n",
    "        if n_instances > 0:\n",
    "            # count each class\n",
    "            unique_class_labels, class_counts = np.unique(y, return_counts=True)\n",
    "            # subtract class entropy from current score for each class\n",
    "            class_counts = np.divide(class_counts, n_instances)\n",
    "            class_counts = np.power(class_counts, 2)\n",
    "            sum = np.sum(class_counts)\n",
    "            return 1 - sum\n",
    "        else:\n",
    "            # y is empty, therefore considered pure\n",
    "            raise ValueError(\"y empty\")\n",
    "\n",
    "    def gini_gain(self, y, y_subs):\n",
    "        \"\"\"Get gini score of a split, i.e. the gain from parent to children.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : 1d array\n",
    "            array of class labels at parent\n",
    "        y_subs : list of 1d array like\n",
    "            list of array of class labels, one array per child\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        score : float\n",
    "            gini score of the split from parent class labels to children. Note a\n",
    "            higher score means better gain,\n",
    "            i.e. a better split\n",
    "        \"\"\"\n",
    "        if y.ndim != 1:\n",
    "            raise ValueError()\n",
    "        # find number of instances overall\n",
    "        parent_n_instances = y.shape[0]\n",
    "        # if parent has no instances then is pure\n",
    "        if parent_n_instances == 0:\n",
    "            for child in y_subs:\n",
    "                if len(child) > 0:\n",
    "                    raise ValueError(\"children populated but parent empty\")\n",
    "            return 0.5\n",
    "        # find gini for parent node\n",
    "        score = self.gini(y)\n",
    "        # sum the children's gini scores\n",
    "        for index in range(len(y_subs)):\n",
    "            child_class_labels = y_subs[index]\n",
    "            # ignore empty children\n",
    "            if len(child_class_labels) > 0:\n",
    "                # find gini score for this child\n",
    "                child_score = self.gini(child_class_labels)\n",
    "                # weight score by proportion of instances at child compared to\n",
    "                # parent\n",
    "                child_size = len(child_class_labels)\n",
    "                child_score *= child_size / parent_n_instances\n",
    "                # add to cumulative sum\n",
    "                score -= child_score\n",
    "        return score\n",
    "\n",
    "    def _build_tree(self, X, y, depth, node_id, parent_target_value=None):\n",
    "\n",
    "        # If the data reaching the node is empty\n",
    "        if len(X) == 0:\n",
    "            leaf_label = parent_target_value\n",
    "            leaf_distribution = {}\n",
    "            leaf = Node(\n",
    "                node_id=node_id,\n",
    "                _is_leaf=True,\n",
    "                label=leaf_label,\n",
    "                class_distribution=leaf_distribution,\n",
    "            )\n",
    "\n",
    "        # Target value in current node\n",
    "        target_value = self._find_target_value(y)\n",
    "        class_distribution = {\n",
    "            label: count / len(y)\n",
    "            for label, count in zip(*np.unique(y, return_counts=True))\n",
    "        }\n",
    "\n",
    "        # If min sample splits is reached\n",
    "        if self.min_samples_split >= len(X):\n",
    "            leaf_label = target_value\n",
    "            leaf = Node(\n",
    "                node_id=node_id,\n",
    "                _is_leaf=True,\n",
    "                label=leaf_label,\n",
    "                class_distribution=class_distribution,\n",
    "            )\n",
    "\n",
    "        # If max depth is reached\n",
    "        if (self.max_depth is not None) and (depth >= self.max_depth):\n",
    "            leaf_label = target_value\n",
    "            leaf = Node(\n",
    "                node_id=node_id,\n",
    "                _is_leaf=True,\n",
    "                label=leaf_label,\n",
    "                class_distribution=class_distribution,\n",
    "            )\n",
    "\n",
    "        # Pure node\n",
    "        if len(np.unique(y)) == 1:\n",
    "            leaf_label = target_value\n",
    "            leaf = Node(\n",
    "                node_id=node_id,\n",
    "                _is_leaf=True,\n",
    "                label=leaf_label,\n",
    "                class_distribution=class_distribution,\n",
    "            )\n",
    "            return leaf\n",
    "\n",
    "        # Find the best splitter\n",
    "        splitter = self.get_best_splitter(X, y)\n",
    "\n",
    "        # Create root node\n",
    "        node = Node(node_id=node_id, _is_leaf=False, splitter=splitter)\n",
    "\n",
    "        # For each exemplar split the data\n",
    "        labels = list(splitter[0].keys())\n",
    "        measure = list(splitter[1].keys())[0]\n",
    "        X_child = [[] for _ in labels]\n",
    "        y_child = [[] for _ in labels]\n",
    "        for i in range(len(X)):\n",
    "            min_dist = np.inf\n",
    "            id = None\n",
    "            for j in range(len(labels)):\n",
    "                dist = distance(\n",
    "                    X[i],\n",
    "                    splitter[0][labels[j]],\n",
    "                    metric=measure,\n",
    "                    kwargs=splitter[1][measure],\n",
    "                )\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    id = j\n",
    "            X_child[id].append(X[i])\n",
    "            y_child[id].append(y[i])\n",
    "        X_child = [np.array(ele) for ele in X_child]\n",
    "        y_child = [np.array(ele) for ele in y_child]\n",
    "        # For each exemplar, create a branch\n",
    "        for i in range(len(labels)):\n",
    "            child_node_id = node_id + \".\" + str(i)\n",
    "            child_node = self._build_tree(\n",
    "                X_child[i],\n",
    "                y_child[i],\n",
    "                depth=depth + 1,\n",
    "                node_id=child_node_id,\n",
    "                parent_target_value=target_value,\n",
    "            )\n",
    "            node.children[labels[i]] = child_node\n",
    "\n",
    "        return node\n",
    "\n",
    "    def _find_target_value(self, y):\n",
    "        \"\"\"Get the class label of highest frequency.\"\"\"\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        # Find the index of the maximum count\n",
    "        max_index = np.argmax(counts)\n",
    "        mode_value = unique[max_index]\n",
    "        # mode_count = counts[max_index]\n",
    "        return mode_value\n",
    "\n",
    "    def get_best_splitter(self, X, y):\n",
    "        max_gain = float(\"-inf\")\n",
    "        best_splitter = None\n",
    "        for _ in range(self.n_splitters):\n",
    "            splitter = self.get_candidate_splitter(X, y)\n",
    "            labels = list(splitter[0].keys())\n",
    "            measure = list(splitter[1].keys())[0]\n",
    "            y_subs = [[] for k in range(len(labels))]\n",
    "            for j in range(X.shape[0]):\n",
    "                min_dist = float(\"inf\")\n",
    "                sub = None\n",
    "                for k in range(len(labels)):\n",
    "                    dist = distance(\n",
    "                        X[j],\n",
    "                        splitter[0][labels[k]],\n",
    "                        metric=measure,\n",
    "                        kwargs=splitter[1][measure],\n",
    "                    )\n",
    "                    if dist < min_dist:\n",
    "                        min_dist = dist\n",
    "                        sub = k\n",
    "                y_subs[sub].append(y[j])\n",
    "            y_subs = [np.array(ele) for ele in y_subs]\n",
    "            gini_index = self.gini_gain(y, y_subs)\n",
    "            if gini_index > max_gain:\n",
    "                max_gain = gini_index\n",
    "                best_splitter = splitter\n",
    "        return best_splitter\n",
    "\n",
    "    def _fit(self, X, y):\n",
    "        seed = check_random_state(self.random_state)\n",
    "        # Set the unique class labels\n",
    "        self.classes_ = list(np.unique(y))\n",
    "\n",
    "        self.root = self._build_tree(\n",
    "            X, y, depth=0, node_id=\"0\", parent_target_value=None\n",
    "        )\n",
    "        self._is_fitted = True\n",
    "\n",
    "    def _predict(self, X):\n",
    "        if not self._is_fitted:\n",
    "            raise NotFittedError(\n",
    "                f\"This instance of {self.__class__.__name__} has not \"\n",
    "                f\"been fitted yet; please call `fit` first.\"\n",
    "            )\n",
    "        predictions = list()\n",
    "        for i in range(len(X)):\n",
    "            prediction = self.classify(self.root, X[i])\n",
    "            predictions.append(prediction)\n",
    "        predictions = np.array(predictions)\n",
    "        return predictions\n",
    "\n",
    "    def classify(self, treenode, x):\n",
    "        # Classify one data point using the proximity tree\n",
    "        if treenode._is_leaf:\n",
    "            return treenode.label\n",
    "        else:\n",
    "            measure = list(treenode.splitter[1].keys())[0]\n",
    "            branches = list(treenode.splitter[0].keys())\n",
    "            min_dist = np.inf\n",
    "            id = None\n",
    "            for i in range(len(branches)):\n",
    "                dist = distance(\n",
    "                    x,\n",
    "                    treenode.splitter[0][branches[i]],\n",
    "                    metric=measure,\n",
    "                    kwargs=treenode.splitter[1][measure],\n",
    "                )\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    id = i\n",
    "            return self.classify(treenode.children[branches[id]], x)\n",
    "\n",
    "    def _predict_proba(self, X):\n",
    "        if not self._is_fitted:\n",
    "            raise NotFittedError(\n",
    "                f\"This instance of {self.__class__.__name__} has not \"\n",
    "                f\"been fitted yet; please call `fit` first.\"\n",
    "            )\n",
    "        # Get the unique class labels\n",
    "        classes = self.classes_\n",
    "        class_count = len(classes)\n",
    "        probas = []\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            # Classify the data point and find the leaf node\n",
    "            leaf_node = self._find_leaf(self.root, X[i])\n",
    "\n",
    "            # Create probability distribution based on class counts in the leaf node\n",
    "            proba = np.zeros(class_count)\n",
    "            for class_label, class_proba in leaf_node.class_distribution.items():\n",
    "                proba[classes.index(class_label)] = class_proba\n",
    "            probas.append(proba)\n",
    "\n",
    "        return np.array(probas)\n",
    "\n",
    "    def _find_leaf(self, treenode, x):\n",
    "        # Helper function to find the leaf node for a given data point\n",
    "        if treenode._is_leaf:\n",
    "            return treenode\n",
    "        else:\n",
    "            measure = list(treenode.splitter[1].keys())[0]\n",
    "            branches = list(treenode.splitter[0].keys())\n",
    "            min_dist = np.inf\n",
    "            id = None\n",
    "            for i in range(len(branches)):\n",
    "                dist = distance(\n",
    "                    x,\n",
    "                    treenode.splitter[0][branches[i]],\n",
    "                    metric=measure,\n",
    "                    kwargs=treenode.splitter[1][measure],\n",
    "                )\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    id = i\n",
    "            return self._find_leaf(treenode.children[branches[id]], x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93f29516-7d9e-43c0-a777-f81950898e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomState(MT19937) at 0x1498710B840"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import check_random_state\n",
    "seed = check_random_state(42)\n",
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f75eb9a-56a2-4de9-be87-e4b860354a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameter_value(self, X):\n",
    "        \"\"\"Generate random parameter values.\n",
    "\n",
    "        For a list of distance measures, generate a dictionary\n",
    "        of parameterized distances.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray of shape (n_cases, n_timepoints)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        distance_param : a dictionary of distances and their\n",
    "        parameters.\n",
    "        \"\"\"\n",
    "        X_std = X.std()\n",
    "        param_ranges = {\n",
    "            \"euclidean\": {},\n",
    "            \"dtw\": {\"window\": (0, 0.25)},\n",
    "            \"ddtw\": {\"window\": (0, 0.25)},\n",
    "            \"wdtw\": {\"g\": (0, 1)},\n",
    "            \"wddtw\": {\"g\": (0, 1)},\n",
    "            \"erp\": {\"g\": (X_std / 5, X_std)},\n",
    "            \"lcss\": {\"epsilon\": (X_std / 5, X_std), \"window\": (0, 0.25)},\n",
    "        }\n",
    "        random_params = {}\n",
    "        for measure, ranges in param_ranges.items():\n",
    "            random_params[measure] = {\n",
    "                param: np.round(np.random.uniform(low, high), 3)\n",
    "                for param, (low, high) in ranges.items()\n",
    "            }\n",
    "        # For TWE\n",
    "        lmbda = np.random.randint(0, 9)\n",
    "        exponent_range = np.arange(1, 6)  # Exponents from -5 to 1 (inclusive)\n",
    "        random_exponent = np.random.choice(exponent_range)\n",
    "        nu = 1 / 10**random_exponent\n",
    "        random_params[\"twe\"] = {\"lmbda\": lmbda, \"nu\": nu}\n",
    "\n",
    "        # For MSM\n",
    "        base = 10\n",
    "        # Exponents from -2 to 2 (inclusive)\n",
    "        exponents = np.arange(-2, 3, dtype=np.float64)\n",
    "        # Randomly select an index from the exponent range\n",
    "        random_index = np.random.randint(0, len(exponents))\n",
    "        c = base ** exponents[random_index]\n",
    "        random_params[\"msm\"] = {\"c\": c}\n",
    "\n",
    "        return random_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e78f103a-f9a3-4ae9-97ff-da46ba2b4bfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m seed \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m rng \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom(seed)\n\u001b[0;32m      3\u001b[0m n \u001b[38;5;241m=\u001b[39m rng\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      4\u001b[0m n\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "seed = check_random_state(42)\n",
    "rng = np.random(seed)\n",
    "n = rng.uniform(3,5)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fb312f1-a2b4-4397-8a98-cb89c109b4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.791"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.random.uniform(0,1),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90189ecf-98f8-4301-8e30-8d7ccfac844c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.796560443700367"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "rng = np.random.default_rng(seed)\n",
    "rng.uniform(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca7d2bd6-7790-4ed7-a5d1-383347667622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db2f53a1-7cc6-4973-88fd-99517de6dda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponent_range = np.arange(1, 6)  # Exponents from -5 to 1 (inclusive)\n",
    "random_exponent = np.random.choice(exponent_range)\n",
    "random_exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b92be5f-5116-45d7-bd4c-26a668c0fe48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
